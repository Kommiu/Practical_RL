{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossentropy method\n",
    "\n",
    "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In google collab, uncomment this:\n",
    "# !wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY = : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_states=500, n_actions=6\n"
     ]
    }
   ],
   "source": [
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create stochastic policy\n",
    "\n",
    "This time our policy should be a probability distribution.\n",
    "\n",
    "```policy[s,a] = P(take action a | in state s)```\n",
    "\n",
    "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
    "\n",
    "Please initialize policy __uniformly__, that is, probabililities of all actions should be equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = np.ones((n_states,n_actions))/n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(policy) in (np.ndarray, np.matrix)\n",
    "assert np.allclose(policy, 1./n_actions)\n",
    "assert np.allclose(np.sum(policy, axis=1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play the game\n",
    "\n",
    "Just like before, but we also record all states and actions we took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(policy, t_max=10**4):\n",
    "    \"\"\"q\n",
    "    Play game until end or for t_max ticks.\n",
    "    :param policy: an array of shape [n_states,n_actions] with action probabilities\n",
    "    :returns: list of states, list of actions and sum of rewards\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0.\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        a = np.random.choice(np.arange(n_actions), p=policy[s])\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # Record state, action and add up reward to states,actions and total_reward accordingly.\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a, r = generate_session(policy)\n",
    "assert type(s) == type(a) == list\n",
    "assert len(s) == len(a)\n",
    "assert type(r) in [float, np.float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7c1b8836a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFgNJREFUeJzt3X+UVeV97/H3t4CixBbF0VAmZsZVNCDiiANKtGRuECTBiCTE+CMNRhKwqWma9qairqvmxruCV28SXclKl78uJHEhEalYa1vESo2mce5g0SiYgIo6BAHRtJqAhvDcP85mHGFgxnPmx+Hh/VrrrNn7OXuf/Z1zznxmn2fv/ZxIKSFJytcf9HUBkqSeZdBLUuYMeknKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMte/rwsAOPLII1NdXV1flyFJ+5WVK1e+mlKq6Wy5qgj6uro6Wlpa+roMSdqvRMSLXVnOrhtJypxBL0mZM+glKXNV0UcvqWf87ne/o7W1le3bt/d1KarAwIEDqa2tZcCAAWWtb9BLGWttbeWwww6jrq6OiOjrclSGlBJbt26ltbWV+vr6sh6j066biLgjIjZHxNPt2o6IiAcjYm3x8/CiPSLi5ohYFxFPRcSYsqqS1C22b9/OkCFDDPn9WEQwZMiQij6VdaWPfj4wZbe2ucBDKaXhwEPFPMDHgOHFbTbw/bIrk9QtDPn9X6WvYadBn1J6BHhtt+ZpwIJiegFwbrv2H6SSnwGDI2JoRRVKkipS7lk3R6eUNhbTrwBHF9PDgJfbLddatEk6QNXV1XHiiSfS0NBAY2NjW/trr73GpEmTGD58OJMmTeL1118HYP78+Vx77bUA3Hvvvaxevbptnaampv3q4sr58+fzq1/9qm3+C1/4QtvvU1dXx6uvvtordVR8emUqfbv4e/6G8YiYHREtEdGyZcuWSss4oDXNb6JpflNfl/GOpqbSTSo8/PDDrFq16l0hPW/ePCZOnMjatWuZOHEi8+bN22O93YO+N/z+97/vtsfaPehvu+02Ro4c2W2P31XlBv2mXV0yxc/NRfsG4APtlqst2vaQUrolpdSYUmqsqel0qAZJmVm6dCkzZ84EYObMmdx7770AHHLIIbzvfe/jpz/9Kffddx9f+9rXaGho4LnnngPg7rvvZty4cRx33HH85Cc/2eNxV6xYwYQJE5g6dSrHH388l156KTt37gRg2bJljB8/njFjxvDpT3+aN998EyjtXV9++eWMGTOGu+++m3Xr1nHmmWdy0kknMWbMmLZt33DDDYwdO5bRo0dzzTXXALB+/XpGjBjBF7/4RU444QQmT57Mtm3bWLx4MS0tLVx00UU0NDSwbdu2vX4i+dGPfsS4ceNoaGhgzpw53frPBso/vfI+YCYwr/i5tF37ZRFxF3Aq8J/tungk9bHu/uS34uIVnS4TEUyePJmIYM6cOcyePRuATZs2MXRo6RDe+9//fjZt2gTAZz7zmbZ1zznnHM4++2xmzJjR1rZjxw6am5t54IEH+PrXv87y5cv32GZzczOrV6/mgx/8IFOmTGHJkiU0NTVx3XXXsXz5cgYNGsT111/Pt771La6++moAhgwZwhNPPAHAqaeeyty5c5k+fTrbt29n586dLFu2jLVr19Lc3ExKiXPOOYdHHnmEY445hrVr17Jw4UJuvfVWzjvvPO655x4++9nP8t3vfpcbb7zxXV1Wu1uzZg2LFi3iscceY8CAAXzpS1/izjvv5HOf+1ynz21XdRr0EbEQaAKOjIhW4BpKAf/jiJgFvAicVyz+APBxYB3wW+Dz3VappP3So48+yrBhw9i8eTOTJk3iQx/6EBMmTHjXMhHR5TNLPvnJTwJwyimnsH79+g6XGTduHMceeywAF1xwAY8++igDBw5k9erVnH766QC8/fbbjB8/vm2dXf9g3njjDTZs2MD06dOB0sVKUPo0sGzZMk4++WQA3nzzTdauXcsxxxxDfX09DQ0NndbVkYceeoiVK1cyduxYALZt28ZRRx3V5fW7otOgTyldsJe7JnawbAL+otKiJPWMruyBd7dhw0rnYxx11FFMnz6d5uZmJkyYwNFHH83GjRsZOnQoGzdu7HK4HXzwwQD069ePHTt2dLjM7v80IoKUEpMmTWLhwoUdrjNo0KB9bjelxBVXXMGcOXPe1b5+/fq2mnbVtW3btk5/j/aPO3PmTL75zW92eZ33yrFuJPWY3/zmN7zxxhtt08uWLWPUqFFAqVtmwYLSWdoLFixg2rRpe6x/2GGHta3/XjQ3N/PCCy+wc+dOFi1axBlnnMFpp53GY489xrp169rq+eUvf9nhNmtra9uOGbz11lv89re/5ayzzuKOO+5o69ffsGEDmzdv3mP991r/xIkTWbx4cdtjvfbaa7z4YpdGH+4yg15Sj9m0aRNnnHEGJ510EuPGjWPq1KlMmVK6/nLu3Lk8+OCDDB8+nOXLlzN37tw91j///PO54YYbOPnkk9sOiHbF2LFjueyyyxgxYgT19fVMnz6dmpoa5s+fzwUXXMDo0aMZP348zz77bIfr//CHP+Tmm29m9OjRfPjDH+aVV15h8uTJXHjhhYwfP54TTzyRGTNmdBriF198MZdeemnbwdiOjBw5kuuuu47JkyczevRoJk2axMaN3XtoM0q9LX2rsbEx7U/nxlabXQfY+uJjeYd2nVq5YkVfViFKB/pGjBjR12X0qhUrVnDjjTdy//3393Up3aqj1zIiVqaU9n6kt+AevSRlztErJWWlqamJJi/Yexf36CUpcwa9JGXOoJekzBn0kpQ5g15Sj7rpppsYNWoUJ5xwAt/5znfa2h2meD8apliS9ubpp5/m1ltvpbm5mSeffJL777+/7cpUhynuPQa9pB6zZs0aTj31VA499FD69+/PRz7yEZYsWQI4THF71TpMsaT9UXefX97J1c+jRo3iqquuYuvWrRxyyCE88MADbUP2OkxxSVUMUyxJ5RoxYgSXX345kydPZtCgQTQ0NNCvX789lnOY4j4eplhSRvpg/KFZs2Yxa9YsAK688kpqa2sBHKa43eM6TLGk/dqu4XdfeukllixZwoUXXgg4TPEuDlMsab/3qU99ipEjR/KJT3yC733vewwePBhwmOJdHKZYXeIwxdobhynOh8MUS5L2yoOxkrLiMMV7co9eylw1dM+qMpW+hga9lLGBAweydetWw34/llJi69atbefzl8OuGyljtbW1tLa2smXLlr4uRRUYOHBg2/UH5TDopYwNGDCA+vr6vi5DfcyuG0nKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMmfQS1LmKgr6iPhqRDwTEU9HxMKIGBgR9RHxeESsi4hFEXFQdxUrSXrvyg76iBgG/CXQmFIaBfQDzgeuB76dUvoT4HVgVncUKkkqT6VdN/2BQyKiP3AosBH4KLC4uH8BcG6F25AkVaDsoE8pbQBuBF6iFPD/CawEfp1S2vWNva3AsEqLlCSVr5Kum8OBaUA98MfAIGDKe1h/dkS0RESLI+tJUs+ppOvmTOCFlNKWlNLvgCXA6cDgoisHoBbY0NHKKaVbUkqNKaXGmpqaCsqQJO1LJUH/EnBaRBwaEQFMBFYDDwMzimVmAksrK1GSVIlK+ugfp3TQ9Qng58Vj3QJcDvx1RKwDhgC3d0OdkqQyVfTFIymla4Brdmt+HhhXyeNKkrqPV8ZKUuYMeknKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMmfQS1LmDHpJypxBL0mZM+glKXMGvSRlzqCXpMwZ9JKUOYNekjJn0EtS5gx6ScqcQS9JmTPoJSlzBr0kZc6gl6TMGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMmfQS1LmKgr6iBgcEYsj4tmIWBMR4yPiiIh4MCLWFj8P765iJUnvXaV79DcB/5xS+hBwErAGmAs8lFIaDjxUzEuS+kjZQR8RfwRMAG4HSCm9nVL6NTANWFAstgA4t9IiJUnlq2SPvh7YAvzfiPiPiLgtIgYBR6eUNhbLvAIcXWmRkqTyVRL0/YExwPdTSicDv2G3bpqUUgJSRytHxOyIaImIli1btlRQhiRpXyoJ+lagNaX0eDG/mFLwb4qIoQDFz80drZxSuiWl1JhSaqypqamgDEnSvpQd9CmlV4CXI+L4omkisBq4D5hZtM0EllZUoSSpIv0rXP/LwJ0RcRDwPPB5Sv88fhwRs4AXgfMq3IYkqQIVBX1KaRXQ2MFdEyt5XElS9/HKWEnKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMmfQS1LmDHpJypxBL0mZM+glKXMGvSRlzqCXpMwZ9JKUOYNekjJn0EtS5gx6ScqcQS9JmTPoJSlzBr0kZc6gl6TM9e/rAg5UdXP/sex118+b2o2VSMqde/SSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUpc55euR/a/dTMVw7a2mF7Rzw1UzrwuEcvSZkz6CUpcwa9JGWu4qCPiH4R8R8RcX8xXx8Rj0fEuohYFBEHVV6mJKlc3bFH/xVgTbv564Fvp5T+BHgdmNUN25AklamioI+IWmAqcFsxH8BHgcXFIguAcyvZhiSpMpXu0X8H+FtgZzE/BPh1SmlHMd8KDKtwG5KkCpQd9BFxNrA5pbSyzPVnR0RLRLRs2bKl3DIkSZ2oZI/+dOCciFgP3EWpy+YmYHBE7LoQqxbY0NHKKaVbUkqNKaXGmpqaCsqQJO1L2UGfUroipVSbUqoDzgf+NaV0EfAwMKNYbCawtOIqJUll64nz6C8H/joi1lHqs7+9B7YhSeqibhnrJqW0AlhRTD8PjOuOx1X3q+QrDMGxcqT9kVfGSlLmDHpJypxBL0mZM+glKXMGvSRlzqCXpMwZ9JKUOYNekjJn0EtS5gx6ScqcQS9JmTPoJSlzBr0kZc6gl6TMGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMmfQS1LmDHpJypxBL0mZM+glKXMGvSRlzqCXpMwZ9JKUOYNekjJn0EtS5soO+oj4QEQ8HBGrI+KZiPhK0X5ERDwYEWuLn4d3X7mSpPeqkj36HcDfpJRGAqcBfxERI4G5wEMppeHAQ8W8JKmPlB30KaWNKaUniuk3gDXAMGAasKBYbAFwbqVFSpLK1y199BFRB5wMPA4cnVLaWNz1CnD0XtaZHREtEdGyZcuW7ihDktSBioM+It4H3AP8VUrpv9rfl1JKQOpovZTSLSmlxpRSY01NTaVlSJL2on8lK0fEAEohf2dKaUnRvCkihqaUNkbEUGBzpUVWq7q5/9jXJUhSpyo56yaA24E1KaVvtbvrPmBmMT0TWFp+eZKkSlWyR3868GfAzyNiVdF2JTAP+HFEzAJeBM6rrERJUiXKDvqU0qNA7OXuieU+riSpe3llrCRlrqKDsTrwdOUA9F3PbwXg/N2WXT9vao/UJGnf3KOXpMwZ9JKUOYNekjJn0EtS5gx6ScqcQS9JmTPoJSlzBr0kZc6gl6TMGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUpcwf8ePR+wbek3LlHL0mZO+D36NV7Kvn05LdTSeVzj16SMrff79Hbxy5J++YevSRlzqCXpMwZ9JKUOYNekjJn0EtS5gx6Scrcfn96pQ4MXmwllc89eknKnHv0yp6fBnSgc49ekjLXI0EfEVMi4hcRsS4i5vbENiRJXdPtQR8R/YDvAR8DRgIXRMTI7t6OJKlreqKPfhywLqX0PEBE3AVMA1b3wLYkVZn9caDBSo7FVPr79sZxoJ7ouhkGvNxuvrVokyT1gUgpde8DRswApqSUvlDM/xlwakrpst2Wmw3MLmaPB37RrYWU50jg1b4uohPVXqP1Vaba64Pqr/FAqu+DKaWazhbqia6bDcAH2s3XFm3vklK6BbilB7ZftohoSSk19nUd+1LtNVpfZaq9Pqj+Gq1vTz3RdfP/gOERUR8RBwHnA/f1wHYkSV3Q7Xv0KaUdEXEZ8C9AP+COlNIz3b0dSVLX9MiVsSmlB4AHeuKxe1hVdSXtRbXXaH2Vqfb6oPprtL7ddPvBWElSdXEIBEnK3AEb9BFxUkT8e0T8PCL+ISL+sN19VxTDN/wiIs5q195rQztERENE/CwiVkVES0SMK9ojIm4uangqIsa0W2dmRKwtbjN7uL5FRW2rImJ9RKxqd1+fP3/ttvnliHg2Ip6JiP9dTTVGxLURsaHd8/jxaqqv3Tb/JiJSRBxZzFfFe7DY3jeKGlZFxLKI+ONqqjEibijef09FxN9HxOB29/Xea5xSOiBvlM4O+kgxfQnwjWJ6JPAkcDBQDzxH6aByv2L6WOCgYpmRPVjfMuBjxfTHgRXtpv8JCOA04PGi/Qjg+eLn4cX04b30XP4f4Opqev6KWv4bsBw4uJg/qppqBK4F/nsH7VVRX1HLByidWPEicGS1vQeBP2w3/ZfA31VTjcBkoH8xfT1wfV+8xgfsHj1wHPBIMf0g8KliehpwV0rprZTSC8A6SsM6tA3tkFJ6G9g1tENPScCuTxl/BPyqXX0/SCU/AwZHxFDgLODBlNJrKaXXi99pSg/WB5T2nIDzgIXt6quG5w/gz4F5KaW3AFJKm6uwxo5UU33fBv6W0vuxfX1V8R5MKf1Xu9lB7eqsihpTSstSSjuK2Z9Ruq5oV3299hofyEH/DO88gZ/mnYu89jaEQ28P7fBXwA0R8TJwI3BFldW3y58Cm1JKa6uwvuOAP42IxyPi3yJibBXWeFnxsf6OiDi8muqLiGnAhpTSk7vdVRX17RIR/6v4O7kIuLoaayxcQulTBvuoo0fqy/qLRyJiOfD+Du66itKTfnNE/A9KF3S93Zu1Qaf1TQS+mlK6JyLOA24HzqyW+lJKS4vpC3hnb77XdfIc9qf0Ef00YCzw44g4thfL66y+7wPfoLQX+g1KXWCX9F51ndZ3JaWuhz7V2fswpXQVcFVEXAFcBlxTTfUVy1wF7ADu7M3adsk66FNKnQXjZICIOA7YNYTcvoZw6HRoh+6qLyJ+AHylmL0buK2T+jYATbu1r+ip+ooa+wOfBE5p19xrz19nNUbEnwNLUqlTtDkidlIaZ6QqXuPdar0VuL+Y7fP6IuJESn3HT5Z656gFnojSSQG99h7cV40duJPS9TvX9GaNXfg7uRg4G5hYvBfZR33so72iIg/IG+8cmPsD4AfAJcX8Cbz7IMnzlA6Q9C+m63nnIMkJPVjfGqCpmJ4IrCymp/Lug0zNRfsRwAuUDjAdXkwf0cPP4RTg33Zrq4rnr6jlUuB/FtPHUfpIHNVSIzC03fRXKfXZVtVz2K6+9bxzMLaa3oPD201/GVhcTTUWfyOrgZq+/Dvp8TdItd4o7S3/srjNo7h4rLjvKkpHvn9BceZL0f7xYvnnKH0s68n6zgBWFi/048ApRXtQ+mKX54CfA43t1rmE0kGddcDne+E5nA9c2kF7nz9/xfYOAn4EPA08AXy0mmoEfli8hk9R6j4cWk317Vbret4J+mp6D95TvL5PAf8ADKumGottvAysKm5/1xevsVfGSlLmDuSzbiTpgGDQS1LmDHpJypxBL0mZM+glKXMGvSRlzqCXpMwZ9JKUuf8PT6zM878tZCoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see the initial reward distribution\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sample_rewards = [generate_session(policy, t_max=1000)[-1] for _ in range(200)]\n",
    "\n",
    "plt.hist(sample_rewards, bins=20)\n",
    "plt.vlines([np.percentile(sample_rewards, 50)], [0], [\n",
    "           100], label=\"50'th percentile\", color='green')\n",
    "plt.vlines([np.percentile(sample_rewards, 90)], [0], [\n",
    "           100], label=\"90'th percentile\", color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossentropy method steps (2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you're confused, see examples below. Please don't assume that states are integers (they'll get different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "\n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "    \n",
    "    for i,r in enumerate(rewards_batch):\n",
    "        if r >= reward_threshold:\n",
    "            elite_states.extend(states_batch[i])\n",
    "            elite_actions.extend(actions_batch[i])\n",
    "    \n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "states_batch = [\n",
    "    [1, 2, 3],  # game1\n",
    "    [4, 2, 0, 2],  # game2\n",
    "    [3, 1]  # game3\n",
    "]\n",
    "\n",
    "actions_batch = [\n",
    "    [0, 2, 4],  # game1\n",
    "    [3, 2, 0, 1],  # game2\n",
    "    [3, 3]  # game3\n",
    "]\n",
    "rewards_batch = [\n",
    "    3,  # game1\n",
    "    4,  # game2\n",
    "    5,  # game3\n",
    "]\n",
    "\n",
    "test_result_0 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=0)\n",
    "test_result_40 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=30)\n",
    "test_result_90 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=90)\n",
    "test_result_100 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=100)\n",
    "\n",
    "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
    "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
    "assert np.all(test_result_40[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
    "    np.all(test_result_40[1] == [3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 30 you should only select states/actions from two first\"\n",
    "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
    "    np.all(test_result_90[1] == [3, 3]),\\\n",
    "    \"For percentile 90 you should only select states/actions from one game\"\n",
    "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
    "    np.all(test_result_100[1] == [3, 3]),\\\n",
    "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(elite_states, elite_actions):\n",
    "    \"\"\"\n",
    "    Given old policy and a list of elite states/actions from select_elites,\n",
    "    return new updated policy where each action probability is proportional to\n",
    "\n",
    "    policy[s_i,a_i] ~ #[occurences of si and ai in elite states/actions]\n",
    "\n",
    "    Don't forget to normalize policy to get valid probabilities and handle 0/0 case.\n",
    "    In case you never visited a state, set probabilities for all actions to 1./n_actions\n",
    "\n",
    "    :param elite_states: 1D list of states from elite sessions\n",
    "    :param elite_actions: 1D list of actions from elite sessions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    new_policy = np.zeros([n_states, n_actions]) \n",
    "\n",
    "    for i,j in zip(elite_states, elite_actions):\n",
    "        new_policy[i,j] += 1\n",
    "        \n",
    "    new_policy[list(set(range(n_states)).difference(elite_states))] = 1\n",
    "    new_policy /= new_policy.sum(axis=1).reshape((-1,1))\n",
    "    \n",
    "    # Don't forget to set 1/n_actions for all actions in unvisited states.\n",
    "\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "elite_states, elite_actions = ([1, 2, 3, 4, 2, 0, 2, 3, 1], [\n",
    "                               0, 2, 4, 3, 2, 0, 1, 3, 3])\n",
    "\n",
    "\n",
    "new_policy = update_policy(elite_states, elite_actions)\n",
    "\n",
    "assert np.isfinite(new_policy).all(\n",
    "), \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
    "assert np.all(\n",
    "    new_policy >= 0), \"Your new policy can't have negative action probabilities\"\n",
    "assert np.allclose(new_policy.sum(\n",
    "    axis=-1), 1), \"Your new policy should be a valid probability distribution over actions\"\n",
    "reference_answer = np.array([\n",
    "    [1.,  0.,  0.,  0.,  0.],\n",
    "    [0.5,  0.,  0.,  0.5,  0.],\n",
    "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
    "    [0.,  0.,  0.,  0.5,  0.5]])\n",
    "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def show_progress(rewards_batch, log, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset policy just in case\n",
    "policy = np.ones([n_states, n_actions])/n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 16.4 ms, total: 3.43 s\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "sessions = [generate_session(policy) for _  in range(n_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 69.3 ms, total: 12.7 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sessions = Parallel(n_jobs=2)(delayed(generate_session)(policy) for _ in range(n_sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 9.95 ms, total: 3.43 s\n",
      "Wall time: 3.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sessions = []\n",
    "for _ in range(n_sessions):\n",
    "    sessions.append(generate_session(policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-1b5507f7ac7a>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(policy, t_max)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnew_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sessions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ab33fce52d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sessions = [generate_session(policy) for _  in range(n_sessions)]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0melite_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melite_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_elites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sessions' is not defined"
     ]
    }
   ],
   "source": [
    "n_sessions = 250  # sample this many sessions\n",
    "percentile = 50  # take this percent of session with highest rewards\n",
    "learning_rate = 0.5  # add this thing to all counts for stability\n",
    "\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    %time sessions = [generate_session(policy) for _  in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "\n",
    "    new_policy = update_policy(elite_states, elite_actions)\n",
    "\n",
    "    policy = learning_rate*new_policy + (1-learning_rate)*policy\n",
    "\n",
    "    # display results on chart\n",
    "    show_progress(rewards_batch, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digging deeper: approximate crossentropy with neural nets\n",
    "\n",
    "![img](https://casd35.wikispaces.com/file/view/digging_deeper_final.jpg/359658499/503x260/digging_deeper_final.jpg)\n",
    "\n",
    "In this section we will train a neural network policy for continuous state space game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f595900cb38>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEjRJREFUeJzt3XGMnVd95vHvs3ZIWGDrhEwtr+2sU/AuSlfFSWdDItAqTUSbpFWdSi1KdlUiFGlYKUigom2TVtqC1EittCW7aHcj3CbFVJSQBmisKC1NTaSKP0iYgDF2TMoARrblxAMkAYqaXYdf/5jjcHcYe+7MnevxHL4f6eq+73nPe+/vJFfPvHPmPb6pKiRJ/fkXq12AJGk8DHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE6NLeCTXJ/k6SQzSe4Y1/tIkhaWcdwHn2Qd8A/AW4GjwOeBW6rqqRV/M0nSgsZ1BX8lMFNVX6+q/wvcD+wc03tJkhawfkyvuxk4MrB/FHjT6TpffPHFtW3btjGVIklrz+HDh/nWt76VUV5jXAG/qCRTwBTAJZdcwvT09GqVIknnnMnJyZFfY1xTNMeArQP7W1rby6pqV1VNVtXkxMTEmMqQpJ9c4wr4zwPbk1ya5BXAzcCeMb2XJGkBY5miqaqTSd4FfBpYB9xXVQfH8V6SpIWNbQ6+qh4BHhnX60uSzsyVrJLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOjXSV/YlOQx8D3gJOFlVk0kuAj4ObAMOA2+rqudGK1OStFQrcQX/C1W1o6om2/4dwN6q2g7sbfuSpLNsHFM0O4HdbXs3cNMY3kOStIhRA76Av03yZJKp1raxqo637WeAjSO+hyRpGUaagwfeUlXHkvw08GiSrwwerKpKUgud2H4gTAFccsklI5YhSZpvpCv4qjrWnk8AnwKuBJ5NsgmgPZ84zbm7qmqyqiYnJiZGKUOStIBlB3ySVyV5zalt4BeBA8Ae4NbW7VbgoVGLlCQt3ShTNBuBTyU59Tp/UVV/k+TzwANJbgO+Cbxt9DIlSUu17ICvqq8Db1yg/dvAdaMUJUkanStZJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4tGvBJ7ktyIsmBgbaLkjya5Kvt+cLWniQfTDKTZH+SK8ZZvCTp9Ia5gv8wcP28tjuAvVW1Hdjb9gFuALa3xxRwz8qUKUlaqkUDvqr+HvjOvOadwO62vRu4aaD9IzXnc8CGJJtWqlhJ0vCWOwe/saqOt+1ngI1tezNwZKDf0db2Y5JMJZlOMj07O7vMMiRJpzPyH1mrqoBaxnm7qmqyqiYnJiZGLUOSNM9yA/7ZU1Mv7flEaz8GbB3ot6W1SZLOsuUG/B7g1rZ9K/DQQPvb2900VwEvDEzlSJLOovWLdUjyMeAa4OIkR4HfB/4QeCDJbcA3gbe17o8ANwIzwA+Ad4yhZknSEBYN+Kq65TSHrlugbwG3j1qUJGl0rmSVpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktSpRQM+yX1JTiQ5MND2viTHkuxrjxsHjt2ZZCbJ00l+aVyFS5LObJgr+A8D1y/QfndV7WiPRwCSXAbcDPxsO+f/JFm3UsVKkoa3aMBX1d8D3xny9XYC91fVi1X1DWAGuHKE+iRJyzTKHPy7kuxvUzgXtrbNwJGBPkdb249JMpVkOsn07OzsCGVIkhay3IC/B3gdsAM4DvzxUl+gqnZV1WRVTU5MTCyzDEnS6Swr4Kvq2ap6qap+CPwJP5qGOQZsHei6pbVJks6yZQV8kk0Du78GnLrDZg9wc5Lzk1wKbAeeGK1ESdJyrF+sQ5KPAdcAFyc5Cvw+cE2SHUABh4F3AlTVwSQPAE8BJ4Hbq+ql8ZQuSTqTRQO+qm5ZoPneM/S/C7hrlKIkSaNzJaskdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnq1KK3SUo/KZ7c9c4F239+6kNnuRJpZXgFL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdWrRgE+yNcljSZ5KcjDJu1v7RUkeTfLV9nxha0+SDyaZSbI/yRXjHoQk6ccNcwV/EnhvVV0GXAXcnuQy4A5gb1VtB/a2fYAbgO3tMQXcs+JVS5IWtWjAV9XxqvpC2/4ecAjYDOwEdrduu4Gb2vZO4CM153PAhiSbVrxySdIZLWkOPsk24HLgcWBjVR1vh54BNrbtzcCRgdOOtrb5rzWVZDrJ9Ozs7BLLliQtZuiAT/Jq4BPAe6rqu4PHqqqAWsobV9WuqpqsqsmJiYmlnCpJGsJQAZ/kPObC/aNV9cnW/OypqZf2fKK1HwO2Dpy+pbVJks6iYe6iCXAvcKiqPjBwaA9wa9u+FXhooP3t7W6aq4AXBqZyJElnyTBf2fdm4DeBLyfZ19p+F/hD4IEktwHfBN7Wjj0C3AjMAD8A3rGiFUuShrJowFfVZ4Gc5vB1C/Qv4PYR65IkjciVrJLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvNT8/9aHVLkFaUQa8JHXKgJekThnwktQpA16SOmXAS1KnhvnS7a1JHkvyVJKDSd7d2t+X5FiSfe1x48A5dyaZSfJ0kl8a5wAkSQsb5ku3TwLvraovJHkN8GSSR9uxu6vqvw92TnIZcDPws8C/Bv4uyb+tqpdWsnBJ0pktegVfVcer6gtt+3vAIWDzGU7ZCdxfVS9W1TeAGeDKlShWkjS8Jc3BJ9kGXA483prelWR/kvuSXNjaNgNHBk47ypl/IEiSxmDogE/yauATwHuq6rvAPcDrgB3AceCPl/LGSaaSTCeZnp2dXcqpkqQhDBXwSc5jLtw/WlWfBKiqZ6vqpar6IfAn/Gga5hiwdeD0La3t/1NVu6pqsqomJyYmRhmDJGkBw9xFE+Be4FBVfWCgfdNAt18DDrTtPcDNSc5PcimwHXhi5UqWJA1jmLto3gz8JvDlJPta2+8CtyTZARRwGHgnQFUdTPIA8BRzd+Dc7h00knT2LRrwVfVZIAsceuQM59wF3DVCXZKkEbmSVZI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvLqXZOjHOM6XVosBL0mdGuYLP6SfKA8fn3p5+1c27VrFSqTReAUvDRgM94X2pbXEgJekTg3zpdsXJHkiyZeSHEzy/tZ+aZLHk8wk+XiSV7T289v+TDu+bbxDkCQtZJgr+BeBa6vqjcAO4PokVwF/BNxdVa8HngNua/1vA55r7Xe3ftKaMH/O3Tl4rWXDfOl2Ad9vu+e1RwHXAv+pte8G3gfcA+xs2wAPAv8rSdrrSOe0yXfuAn4U6u9btUqk0Q01B59kXZJ9wAngUeBrwPNVdbJ1OQpsbtubgSMA7fgLwGtXsmhJ0uKGCviqeqmqdgBbgCuBN4z6xkmmkkwnmZ6dnR315SRJ8yzpLpqqeh54DLga2JDk1BTPFuBY2z4GbAVox38K+PYCr7WrqiaranJiYmKZ5UuSTmeYu2gmkmxo268E3gocYi7of711uxV4qG3vafu0459x/l2Szr5hVrJuAnYnWcfcD4QHqurhJE8B9yf5A+CLwL2t/73AnyeZAb4D3DyGuiVJixjmLpr9wOULtH+dufn4+e3/BPzGilQnSVo2V7JKUqcMeEnqlAEvSZ3ynwtW97yJSz+pvIKXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0a5ku3L0jyRJIvJTmY5P2t/cNJvpFkX3vsaO1J8sEkM0n2J7li3IOQJP24Yf49+BeBa6vq+0nOAz6b5K/bsf9aVQ/O638DsL093gTc054lSWfRolfwNef7bfe89jjTNyjsBD7SzvscsCHJptFLlSQtxVBz8EnWJdkHnAAerarH26G72jTM3UnOb22bgSMDpx9tbZKks2iogK+ql6pqB7AFuDLJvwfuBN4A/AfgIuB3lvLGSaaSTCeZnp2dXWLZkqTFLOkumqp6HngMuL6qjrdpmBeBPwOubN2OAVsHTtvS2ua/1q6qmqyqyYmJieVVL0k6rWHuoplIsqFtvxJ4K/CVU/PqSQLcBBxop+wB3t7uprkKeKGqjo+leknSaQ1zF80mYHeSdcz9QHigqh5O8pkkE0CAfcB/af0fAW4EZoAfAO9Y+bIlSYtZNOCraj9w+QLt156mfwG3j16aJGkUrmSVpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOjV0wCdZl+SLSR5u+5cmeTzJTJKPJ3lFaz+/7c+049vGU7ok6UyWcgX/buDQwP4fAXdX1euB54DbWvttwHOt/e7WT5J0lg0V8Em2AL8M/GnbD3At8GDrshu4qW3vbPu049e1/pKks2j9kP3+B/DbwGva/muB56vqZNs/Cmxu25uBIwBVdTLJC63/twZfMMkUMNV2X0xyYFkjOPddzLyxd6LXcUG/Y3Nca8u/STJVVbuW+wKLBnySXwFOVNWTSa5Z7hvN14re1d5juqomV+q1zyW9jq3XcUG/Y3Nca0+SaVpOLscwV/BvBn41yY3ABcC/Av4nsCHJ+nYVvwU41vofA7YCR5OsB34K+PZyC5QkLc+ic/BVdWdVbamqbcDNwGeq6j8DjwG/3rrdCjzUtve0fdrxz1RVrWjVkqRFjXIf/O8Av5Vkhrk59ntb+73Aa1v7bwF3DPFay/4VZA3odWy9jgv6HZvjWntGGlu8uJakPrmSVZI6teoBn+T6JE+3la/DTOecU5Lcl+TE4G2eSS5K8miSr7bnC1t7knywjXV/kitWr/IzS7I1yWNJnkpyMMm7W/uaHluSC5I8keRLbVzvb+1drMzudcV5ksNJvpxkX7uzZM1/FgGSbEjyYJKvJDmU5OqVHNeqBnySdcD/Bm4ALgNuSXLZata0DB8Grp/Xdgewt6q2A3v50d8hbgC2t8cUcM9ZqnE5TgLvrarLgKuA29v/m7U+theBa6vqjcAO4PokV9HPyuyeV5z/QlXtGLglcq1/FmHujsS/qao3AG9k7v/dyo2rqlbtAVwNfHpg/07gztWsaZnj2AYcGNh/GtjUtjcBT7ftDwG3LNTvXH8wd5fUW3saG/AvgS8Ab2Juocz61v7y5xL4NHB1217f+mW1az/NeLa0QLgWeBhID+NqNR4GLp7XtqY/i8zdQv6N+f/dV3Jcqz1F8/Kq12ZwRexatrGqjrftZ4CNbXtNjrf9+n458DgdjK1NY+wDTgCPAl9jyJXZwKmV2eeiUyvOf9j2h15xzrk9LoAC/jbJk20VPKz9z+KlwCzwZ21a7U+TvIoVHNdqB3z3au5H7Zq9VSnJq4FPAO+pqu8OHlurY6uql6pqB3NXvFcCb1jlkkaWgRXnq13LmLylqq5gbpri9iT/cfDgGv0srgeuAO6pqsuBf2TebeWjjmu1A/7UqtdTBlfErmXPJtkE0J5PtPY1Nd4k5zEX7h+tqk+25i7GBlBVzzO3YO9q2srsdmihldmc4yuzT604Pwzcz9w0zcsrzluftTguAKrqWHs+AXyKuR/Ma/2zeBQ4WlWPt/0HmQv8FRvXagf854Ht7S/9r2BupeyeVa5pJQyu5p2/yvft7a/hVwEvDPwqdk5JEuYWrR2qqg8MHFrTY0sykWRD234lc39XOMQaX5ldHa84T/KqJK85tQ38InCANf5ZrKpngCNJ/l1rug54ipUc1znwh4YbgX9gbh7091a7nmXU/zHgOPD/mPuJfBtzc5l7ga8Cfwdc1PqGubuGvgZ8GZhc7frPMK63MPer4X5gX3vcuNbHBvwc8MU2rgPAf2vtPwM8AcwAfwmc39ovaPsz7fjPrPYYhhjjNcDDvYyrjeFL7XHwVE6s9c9iq3UHMN0+j38FXLiS43IlqyR1arWnaCRJY2LAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUqX8GbhF4egJMmCQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kommiu/Projects/hse/RL/venv/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create agent\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "agent = MLPClassifier(hidden_layer_sizes=(20, 20),\n",
    "                      activation='tanh',\n",
    "                      warm_start=True,  # keep progress between .fit(...) calls\n",
    "                      max_iter=1  # make only 1 iteration on each .fit(...)\n",
    "                      )\n",
    "# initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset()]*n_actions, range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(t_max=1000):\n",
    "\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        # predict array of action probabilities\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "\n",
    "        a = np.random.choice(np.arange(n_actions), p=probs)\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 194.600, threshold=200.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-abeee3a75dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-abeee3a75dee>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-7586b4012abe>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# predict array of action probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/hse/RL/venv/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/hse/RL/venv/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/hse/RL/venv/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/hse/RL/venv/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session_pole() for _ in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch,rewards_batch,percentile)\n",
    "\n",
    "    agent.fit(elite_states,elite_actions)\n",
    "    show_progress(rewards_batch, log, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),\n",
    "                           directory=\"videos\", force=True)\n",
    "sessions = [generate_session() for _ in range(100)]\n",
    "env.close()\n",
    "# upload to gym\n",
    "# gym.upload(\"./videos/\",api_key=\"<your_api_key>\") #you'll need me later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.2.6364.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(\n",
    "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1]))  # this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you change different percentile and different n_samples.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to upload the result and get to something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "  * For any environment, upload it to gym and post url in your anytask form.\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (bonus: 4++ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  * __Please list what you did in anytask submission form__\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [mountaincar](https://gym.openai.com/envs/MountainCar-v0), [lunarlander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "* __Please upload the results to openai gym and send links to all submissions in the e-mail__\n",
    "\n",
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Start with [\"Pendulum-v0\"](https://github.com/openai/gym/wiki/Pendulum-v0).\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
